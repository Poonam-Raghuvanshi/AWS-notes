<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <title> Kinesis </title>
    <link rel="stylesheet" href="../style.css">
</head>

<body>
    <p class="main-heading">Amazon Kinesis</p>
    <p>
        It makes it easy to <b> collect, process, and analyze real-time, streaming data </b> so you can get timely
        insights and react quickly to new information.

    </p>
    <p>You can ingest real-time data such as <strong> video, audio, application logs, website clickstreams,
            and IoT telemetry data for machine learning, analytics</strong>.</p>
    <p class="heading">FAN out pattern</p>
    <p> By default, the 2MB/second/shard output is shared between all of the applications consuming data from
        the stream. </p>
    <p> <b> If you have multiple consumers retrieving data from a stream in parallel - developers can register stream
            consumers to use enhanced fan-out and receive their own 2MB/second pipe of read throughput per shard, and
            this throughput automatically scales with the number of shards in a stream.</b></p>
    <p class="heading">Kinesis Data Firehose</p>
    <p> Fully managed service and easiest way to reliably <b>load streaming data into data lakes, data stores, and
            analytics tools</b>. It can also batch, compress, transform, and encrypt the data before loading it,
        minimizing the amount of storage used at the destination and increasing security. <b> Kinesis Data Firehose can
            only write to
            S3, Redshift, Opensearch, API Gateway or Splunk</b>. </p>
    <!-- <img src="../images/kn.jpg" /> -->
    <p class="heading">Kinesis Data Analytics</p>
    <p>Easiest way to analyze streaming data in real-time. Kinesis Data Analytics
        enables you to easily and quickly build queries and sophisticated streaming applications in three simple steps:
        setup your streaming data sources, write your queries or streaming applications, and set up your destination for
        processed data.</p>
    <p> <strong> Ingest data from the source as it ingests data either from Kinesis Data Streams or Kinesis Data
            Firehose.You can use Kinesis Data Analytics to transform and analyze streaming data in real-time with Apache
            Flink ( 50 GB of running application storage per Kinesis Processing Unit (KPU)).</strong></p>
    <p>
        <strong> Use cases -</strong> streaming ETL, continuous metric generation, responsive real-time analytics, and
        interactive querying of data streams.
    </p>

    <p>When a Kinesis data stream is configured as the source of a Firehose delivery stream, Firehoseâ€™s PutRecord and
        PutRecordBatch operations are disabled and Kinesis Agent cannot write to Firehose delivery stream directly. Data
        needs to be added to the Kinesis data stream through the Kinesis Data Streams PutRecord and PutRecords
        operations instead.</p>

    <p class="heading">Kinesis Data Streams Retention period</p>
    <p> A Kinesis data stream is an ordered sequence of data records meant to be written to and read from in real-time.
        Data
        records are therefore stored in shards in your stream temporarily. The time period from when a record is added
        to when it is no longer accessible is called the retention period. <strong> A Kinesis data stream stores record
            from 24
            hours by default, up to 8760 hours (365 days).</strong></p>
    <p class="heading">Drawback</p>
    <p> For Kinesis Data Streams, you have to manually allocate the shards for scaling the data ingestion
        process. </p>
    <p class="heading">Use cases</p>
    <ul>
        <li>
            1. Routing related records to the same record processor (as in streaming MapReduce). For example, counting
            and
            aggregation are simpler when all records for a given key are routed to the same record processor. </li>
        <li>
            2. Ordering of records. For example, you want to transfer log data from the application host to the
            processing/archival host while maintaining the order of log statements.
        </li>
        <li> 3. Ability for multiple applications to consume the same stream concurrently. For example, you have one
            application that updates a real-time dashboard and another that archives data to Amazon Redshift. You want
            both
            applications to consume data from the same stream concurrently and independently.
        </li>
        <li> 4. Ability to consume records in the same order a few hours later. For example, you have a billing
            application
            and an audit application that runs a few hours behind the billing application. Because Amazon Kinesis Data
            Streams stores data for up to 365 days, you can run the audit application up to 365 days behind the billing
            application.</li>


    </ul>
</body>

</html>